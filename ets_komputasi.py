# -*- coding: utf-8 -*-
"""ETS KOMPUTASI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XlWHDBSeAmvISScxiG8ifNDN8d-E88k2
"""

pip install seaborn scikit-image

import os
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from skimage.transform import resize
from skimage.io import imread
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pandas as pd

# === STEP 1: LOAD CITRA ===
print("=== MEMULAI PROSES LOAD CITRA ===")
Categories = ['blast', 'blight', 'tungro']
flat_data_arr = []
target_arr = []
datadir = '/content/drive/MyDrive/Dataset/Citra Daun Padi'

# Untuk tujuan demonstrasi, jika path tidak ada, buat data dummy
if not os.path.exists(datadir):
    print(f"Path {datadir} tidak ditemukan. Membuat data dummy untuk demonstrasi...")
    # Buat 30 gambar dummy untuk setiap kategori
    for i in range(len(Categories)):
        for _ in range(30):
            fake_img = np.random.rand(150, 150, 3)
            flat_data_arr.append(fake_img.flatten())
            target_arr.append(i)
else:
    for i, category in enumerate(Categories):
        print(f"Memproses kategori: {category}")
        path = os.path.join(datadir, category)
        if not os.path.exists(path):
            print(f"Path {path} tidak ditemukan!")
            continue

        count = 0
        for img in os.listdir(path):
            img_path = os.path.join(path, img)
            if os.path.isfile(img_path):
                try:
                    img_array = imread(img_path)
                    img_resized = resize(img_array, (150, 150, 3))
                    flat_data_arr.append(img_resized.flatten())
                    target_arr.append(i)
                    count += 1
                except Exception as e:
                    print(f"Error memproses {img_path}: {e}")
        print(f"Berhasil memuat {count} gambar untuk kategori {category}")

if not flat_data_arr:
    print("PERINGATAN: Tidak ada gambar yang dimuat. Membuat data dummy...")
    # Buat data dummy jika tidak ada gambar yang dimuat
    for i in range(len(Categories)):
        for _ in range(30):
            fake_img = np.random.rand(150, 150, 3)
            flat_data_arr.append(fake_img.flatten())
            target_arr.append(i)

flat_data = np.array(flat_data_arr)
target = np.array(target_arr)

print(f"Total data: {len(flat_data)}")
print(f"Dimensi data: {flat_data.shape}")
print(f"Distribusi kelas: {pd.Series(target).map({i: cat for i, cat in enumerate(Categories)}).value_counts()}")

# Split data
X_train, X_test, y_train, y_test = train_test_split(flat_data, target, test_size=0.3, random_state=42)
print(f"Data training: {X_train.shape[0]}, Data testing: {X_test.shape[0]}")

# Baseline model tanpa optimasi
print("\n=== BASELINE MODEL (TANPA OPTIMASI) ===")
baseline_start = time.time()
clf_baseline = GaussianNB()
clf_baseline.fit(X_train, y_train)
y_pred_baseline = clf_baseline.predict(X_test)
baseline_acc = accuracy_score(y_test, y_pred_baseline)
baseline_time = time.time() - baseline_start
print(f"Baseline accuracy: {baseline_acc:.4f}")
print(f"Waktu eksekusi: {baseline_time:.4f} detik")

# Definisi classifier
clf = GaussianNB()

# === STEP 2: DEFINISI ALGORITMA OPTIMASI ===
def run_algorithms(X_train, y_train, X_test, y_test, verbose=True):
    n_features = X_train.shape[1]

    # Hyper-parameters
    pop_size = 20         # Ukuran populasi GA & PSO
    generations = 15      # Jumlah generasi/iterasi
    n_ants = 20           # Jumlah semut

    print("\n=== MEMULAI OPTIMASI FITUR ===")
    print(f"Jumlah fitur awal: {n_features}")

    def GA(pop_size=pop_size, generations=generations, mutation_rate=0.1):
        if verbose:
            print("\nMenjalankan Genetic Algorithm...")

        # Inisialisasi populasi
        population = np.random.randint(2, size=(pop_size, n_features))
        history = []
        selected_features_history = []
        best_mask = None
        best_score = -np.inf

        def fitness(ind):
            idx = np.where(ind == 1)[0]
            if len(idx) == 0:
                return 0.0
            try:
                clf.fit(X_train[:, idx], y_train)
                return accuracy_score(y_test, clf.predict(X_test[:, idx]))
            except:
                return 0.0

        # Evolusi populasi selama beberapa generasi
        for gen in range(generations):
            scores = [fitness(ind) for ind in population]
            max_score = max(scores)
            history.append(max_score)

            best_idx = np.argmax(scores)
            if scores[best_idx] > best_score:
                best_score = scores[best_idx]
                best_mask = population[best_idx].copy()

            selected_features = sum(best_mask) if best_mask is not None else 0
            selected_features_history.append(selected_features)

            if verbose and gen % 5 == 0:
                print(f"  Generasi {gen}: Akurasi terbaik = {max_score:.4f}, Fitur = {selected_features}/{n_features}")

            # Seleksi (tournament selection)
            parents = []
            for _ in range(2):
                idx = np.random.choice(pop_size, 3, replace=False)
                parent_idx = idx[np.argmax([scores[i] for i in idx])]
                parents.append(population[parent_idx])

            # Crossover & Mutation
            children = []
            while len(children) < pop_size - 2:
                p1, p2 = parents
                # Crossover dua titik
                points = sorted(np.random.choice(n_features, 2, replace=False))
                child = np.concatenate((p1[:points[0]], p2[points[0]:points[1]], p1[points[1]:]))
                # Mutasi
                child = np.where(np.random.rand(n_features) < mutation_rate, 1 - child, child)
                children.append(child)

            # Update populasi dengan elitisme (simpan 2 individu terbaik)
            elite_indices = np.argsort(scores)[-2:]
            population = np.vstack((population[elite_indices], children))

        # Evaluasi solusi terbaik
        if best_mask is None or not np.any(best_mask):
            return 0.0, history, selected_features_history

        final_idx = np.where(best_mask == 1)[0]
        clf.fit(X_train[:, final_idx], y_train)
        acc = accuracy_score(y_test, clf.predict(X_test[:, final_idx]))

        if verbose:
            print(f"GA selesai. Akurasi final: {acc:.4f}, Fitur terpilih: {len(final_idx)}/{n_features}")

        return acc, history, selected_features_history, final_idx

    def PSO(n_particles=pop_size, iterations=generations, w=0.7, c1=1.5, c2=1.5):
        if verbose:
            print("\nMenjalankan Particle Swarm Optimization...")

        # Inisialisasi partikel
        particles = np.random.rand(n_particles, n_features)
        velocities = np.random.rand(n_particles, n_features) * 0.1 - 0.05  # Velocity kecil & centered
        pbest = particles.copy()
        scores = [0.0] * n_particles
        gbest = particles[0].copy()
        gbest_score = -np.inf
        selected_features_history = []
        history = []

        def fitness(vec):
            mask = vec > 0.5
            if not np.any(mask):
                return 0.0
            try:
                clf.fit(X_train[:, mask], y_train)
                return accuracy_score(y_test, clf.predict(X_test[:, mask]))
            except:
                return 0.0

        # Evaluasi inisial
        for i in range(n_particles):
            scores[i] = fitness(particles[i])
            if scores[i] > gbest_score:
                gbest_score = scores[i]
                gbest = particles[i].copy()

        # Update partikel selama beberapa iterasi
        for it in range(iterations):
            for i in range(n_particles):
                r1, r2 = np.random.rand(n_features), np.random.rand(n_features)
                velocities[i] = w * velocities[i] + c1 * r1 * (pbest[i] - particles[i]) + c2 * r2 * (gbest - particles[i])
                particles[i] += velocities[i]
                particles[i] = np.clip(particles[i], 0, 1)

                score = fitness(particles[i])
                if score > scores[i]:
                    pbest[i] = particles[i].copy()
                    scores[i] = score
                    if score > gbest_score:
                        gbest = particles[i].copy()
                        gbest_score = score

            history.append(gbest_score)
            selected_features = sum(gbest > 0.5)
            selected_features_history.append(selected_features)

            if verbose and it % 5 == 0:
                print(f"  Iterasi {it}: Akurasi terbaik = {gbest_score:.4f}, Fitur = {selected_features}/{n_features}")

        # Evaluasi solusi terbaik
        mask = gbest > 0.5
        if not np.any(mask):
            return 0.0, history, selected_features_history

        final_idx = np.where(mask)[0]
        clf.fit(X_train[:, final_idx], y_train)
        acc = accuracy_score(y_test, clf.predict(X_test[:, final_idx]))

        if verbose:
            print(f"PSO selesai. Akurasi final: {acc:.4f}, Fitur terpilih: {len(final_idx)}/{n_features}")

        return acc, history, selected_features_history, final_idx

    def ACO(n_ants=n_ants, n_iter=generations, evaporation=0.2, alpha=1, beta=0.1):
        if verbose:
            print("\nMenjalankan Ant Colony Optimization...")

        pheromone = np.ones(n_features)
        history = []
        selected_features_history = []
        best_score = -np.inf
        best_solution = None

        def fitness(mask):
            if not np.any(mask):
                return 0.0
            try:
                clf.fit(X_train[:, mask], y_train)
                return accuracy_score(y_test, clf.predict(X_test[:, mask]))
            except:
                return 0.0

        # Iterasi koloni semut
        for it in range(n_iter):
            solutions, scores = [], []

            # Probabilitas pemilihan fitur berdasarkan pheromone
            prob = pheromone ** alpha
            prob = prob / prob.sum() if prob.sum() != 0 else np.ones(n_features) / n_features

            # Tiap semut membangun solusi
            for _ in range(n_ants):
                mask = np.random.rand(n_features) < prob
                if not np.any(mask):  # Pastikan minimal satu fitur terpilih
                    mask[np.random.randint(0, n_features)] = True

                score = fitness(mask)
                solutions.append(mask)
                scores.append(score)

            # Update solusi terbaik
            iter_best_score = max(scores)
            iter_best_solution = solutions[np.argmax(scores)]

            if iter_best_score > best_score:
                best_score = iter_best_score
                best_solution = iter_best_solution.copy()

            history.append(best_score)
            selected_features = sum(best_solution)
            selected_features_history.append(selected_features)

            if verbose and it % 5 == 0:
                print(f"  Iterasi {it}: Akurasi terbaik = {best_score:.4f}, Fitur = {selected_features}/{n_features}")

            # Update pheromone
            pheromone = (1 - evaporation) * pheromone
            for i in range(n_ants):
                pheromone += solutions[i] * scores[i]

            # Normalisasi pheromone untuk stabilitas
            pheromone = pheromone / pheromone.max() if pheromone.max() > 0 else pheromone

        # Evaluasi solusi terbaik
        if best_solution is None or not np.any(best_solution):
            return 0.0, history, selected_features_history

        final_idx = np.where(best_solution)[0]
        clf.fit(X_train[:, final_idx], y_train)
        acc = accuracy_score(y_test, clf.predict(X_test[:, final_idx]))

        if verbose:
            print(f"ACO selesai. Akurasi final: {acc:.4f}, Fitur terpilih: {len(final_idx)}/{n_features}")

        return acc, history, selected_features_history, final_idx

    # Jalankan semua algoritma
    results = {}
    try:
        start = time.time()
        ga_acc, ga_hist, ga_feat_hist, ga_features = GA()
        ga_time = time.time() - start
        results["GA"] = {
            "acc": ga_acc,
            "time": ga_time,
            "hist": ga_hist,
            "feat_hist": ga_feat_hist,
            "features": ga_features
        }
    except Exception as e:
        print(f"Error saat menjalankan GA: {e}")
        results["GA"] = {"acc": 0.0, "time": 0.0, "hist": [], "feat_hist": [], "features": []}

    try:
        start = time.time()
        pso_acc, pso_hist, pso_feat_hist, pso_features = PSO()
        pso_time = time.time() - start
        results["PSO"] = {
            "acc": pso_acc,
            "time": pso_time,
            "hist": pso_hist,
            "feat_hist": pso_feat_hist,
            "features": pso_features
        }
    except Exception as e:
        print(f"Error saat menjalankan PSO: {e}")
        results["PSO"] = {"acc": 0.0, "time": 0.0, "hist": [], "feat_hist": [], "features": []}

    try:
        start = time.time()
        aco_acc, aco_hist, aco_feat_hist, aco_features = ACO()
        aco_time = time.time() - start
        results["ACO"] = {
            "acc": aco_acc,
            "time": aco_time,
            "hist": aco_hist,
            "feat_hist": aco_feat_hist,
            "features": aco_features
        }
    except Exception as e:
        print(f"Error saat menjalankan ACO: {e}")
        results["ACO"] = {"acc": 0.0, "time": 0.0, "hist": [], "feat_hist": [], "features": []}

    return results, baseline_acc, baseline_time

# === STEP 3: EKSEKUSI DAN VISUALISASI ===
results, baseline_acc, baseline_time = run_algorithms(X_train, y_train, X_test, y_test)

# Tampilkan ringkasan hasil
print("\n=== RINGKASAN HASIL OPTIMASI ===")
print(f"{'Algoritma':<10} {'Akurasi':<10} {'Waktu (s)':<10} {'Fitur':<10}")
print("-" * 40)
print(f"{'Baseline':<10} {baseline_acc:.4f} {baseline_time:.4f}s {X_train.shape[1]}")

for name, res in results.items():
    if res['features'] is not None and len(res['features']) > 0:
        num_features = len(res['features'])
    else:
        num_features = 0
    print(f"{name:<10} {res['acc']:.4f} {res['time']:.4f}s {num_features}")

# === EVALUASI MODEL TERBAIK ===
best_algo = max(results.items(), key=lambda x: x[1]['acc'])[0]
print(f"\nModel terbaik: {best_algo} dengan akurasi {results[best_algo]['acc']:.4f}")

if results[best_algo]['features'] is not None and len(results[best_algo]['features']) > 0:
    best_features = results[best_algo]['features']
    best_clf = GaussianNB()
    best_clf.fit(X_train[:, best_features], y_train)
    y_pred = best_clf.predict(X_test[:, best_features])

    print("\n=== EVALUASI MODEL TERBAIK ({best_algo}) ===")
    print(f"Classification Report:")
    print(classification_report(y_test, y_pred, target_names=Categories))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    print("Confusion Matrix:")
    print(cm)

# === VISUALISASI HASIL ===
# Set style
plt.style.use('seaborn-v0_8-darkgrid')
colors = {'GA': '#ff7f0e', 'PSO': '#2ca02c', 'ACO': '#d62728', 'Baseline': '#1f77b4'}

# Gabungkan semua grafik
fig = plt.figure(figsize=(18, 15))
fig.suptitle('Perbandingan Algoritma Optimasi (GA vs PSO vs ACO)', fontsize=16, y=0.95)

# 1. Grafik Konvergensi
ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)
for name, res in results.items():
    if res['hist']:
        ax1.plot(res['hist'], label=name, linewidth=2, color=colors[name])
ax1.axhline(y=baseline_acc, color=colors['Baseline'], linestyle='--', label='Baseline')
ax1.set_title("Konvergensi Algoritma", fontsize=14)
ax1.set_xlabel("Iterasi/Generasi", fontsize=12)
ax1.set_ylabel("Akurasi", fontsize=12)
ax1.legend(fontsize=10)
ax1.grid(True, alpha=0.3)

# 2. Grafik Waktu Eksekusi
ax2 = plt.subplot2grid((2, 2), (1, 0))
times = [results[alg]['time'] for alg in results if results[alg]['time'] > 0]
names = [alg for alg in results if results[alg]['time'] > 0]
times.append(baseline_time)
names.append('Baseline')

bar_colors = [colors[name] for name in names]
bars = ax2.bar(names, times, color=bar_colors)
ax2.set_title("Kecepatan Eksekusi", fontsize=14)
ax2.set_ylabel("Waktu (detik)", fontsize=12)
ax2.grid(True, axis='y', alpha=0.3)

for bar in bars:
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,
             f'{height:.2f}s', ha='center', va='bottom', fontsize=10)

# 3. Grafik Akurasi
ax3 = plt.subplot2grid((2, 2), (1, 1))
accuracies = [results[alg]['acc'] for alg in results if results[alg]['acc'] > 0]
names = [alg for alg in results if results[alg]['acc'] > 0]
accuracies.append(baseline_acc)
names.append('Baseline')

bar_colors = [colors[name] for name in names]
bars = ax3.bar(names, accuracies, color=bar_colors)
ax3.set_title("Perbandingan Akurasi", fontsize=14)
ax3.set_ylabel("Akurasi", fontsize=12)
ax3.set_ylim(0, max(accuracies) * 1.1)
ax3.grid(True, axis='y', alpha=0.3)

for bar in bars:
    height = bar.get_height()
    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{height:.4f}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.subplots_adjust(top=0.9)
plt.savefig('perbandingan_algoritma.png', dpi=300, bbox_inches='tight')
plt.show()

# Buat grafik tambahan untuk visualisasi jumlah fitur terpilih
plt.figure(figsize=(10, 6))
for name, res in results.items():
    if res['feat_hist']:
        plt.plot(res['feat_hist'], label=name, linewidth=2, color=colors[name])
plt.axhline(y=X_train.shape[1], color=colors['Baseline'], linestyle='--', label='Baseline (All Features)')
plt.title("Jumlah Fitur Terpilih Selama Iterasi", fontsize=14)
plt.xlabel("Iterasi/Generasi", fontsize=12)
plt.ylabel("Jumlah Fitur", fontsize=12)
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.savefig('fitur_terpilih.png', dpi=300, bbox_inches='tight')
plt.show()

# Tampilkan ringkasan dalam tabel
data = {
    'Algoritma': ['Baseline'] + [alg for alg in results],
    'Akurasi': [baseline_acc] + [results[alg]['acc'] for alg in results],
    'Waktu (s)': [baseline_time] + [results[alg]['time'] for alg in results],
    'Fitur Terpilih': [X_train.shape[1]] + [len(results[alg]['features']) if results[alg]['features'] is not None else 0 for alg in results]
}

df_results = pd.DataFrame(data)
print("\nRingkasan Hasil Perbandingan:")
print(df_results)

# Hitung persentase peningkatan dari baseline
baseline_values = df_results[df_results['Algoritma'] == 'Baseline']
if not baseline_values.empty:
    baseline_acc = baseline_values['Akurasi'].values[0]
    baseline_time = baseline_values['Waktu (s)'].values[0]

    df_results['Peningkatan Akurasi (%)'] = ((df_results['Akurasi'] - baseline_acc) / baseline_acc * 100).round(2)
    df_results['Peningkatan Kecepatan (%)'] = ((baseline_time - df_results['Waktu (s)']) / baseline_time * 100).round(2)
    df_results['Reduksi Fitur (%)'] = ((X_train.shape[1] - df_results['Fitur Terpilih']) / X_train.shape[1] * 100).round(2)

    print("\nAnalisis Peningkatan dari Baseline:")
    print(df_results[['Algoritma', 'Peningkatan Akurasi (%)', 'Peningkatan Kecepatan (%)', 'Reduksi Fitur (%)']])